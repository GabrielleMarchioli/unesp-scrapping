{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "init_libs",
            "metadata": {},
            "outputs": [],
            "source": [
                "import requests\n",
                "from bs4 import BeautifulSoup\n",
                "import pandas as pd\n",
                "import sqlite3\n",
                "import time\n",
                "import re\n",
                "import plotly.express as px\n",
                "import plotly.io as pio\n",
                "\n",
                "pio.renderers.default = \"notebook_connected\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "config",
            "metadata": {},
            "outputs": [],
            "source": [
                "# URL base com filtros aplicados (in√≠cio em 2000-07-26)\n",
                "BASE_URL = \"https://parlamento.gub.uy/noticiasyeventos/noticias?field_noticia_fecha_value%5Bmin%5D=2000-07-26&field_noticia_fecha_value%5Bmax%5D=&field_noticia_cuerpo_value=All&body_value=\"\n",
                "DATABASE_NAME = \"parlamento_uy.db\"\n",
                "HEADERS = {\n",
                "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\"\n",
                "}\n",
                "\n",
                "print(\"Configura√ß√£o pronta! Filtros de data aplicados.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "db_setup",
            "metadata": {},
            "outputs": [],
            "source": [
                "def create_database():\n",
                "    conn = sqlite3.connect(DATABASE_NAME)\n",
                "    cursor = conn.cursor()\n",
                "    cursor.execute(\"\"\"\n",
                "        CREATE TABLE IF NOT EXISTS articles (\n",
                "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
                "            title TEXT,\n",
                "            date TEXT,\n",
                "            category TEXT,\n",
                "            url TEXT UNIQUE,\n",
                "            source TEXT\n",
                "        )\n",
                "    \"\"\")\n",
                "    conn.commit()\n",
                "    conn.close()\n",
                "    print(\"‚úÖ Banco e tabela prontos\")\n",
                "\n",
                "create_database()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "insert_func",
            "metadata": {},
            "outputs": [],
            "source": [
                "def insert_article(title, date, category, url, source=\"Parlamento UY\"):\n",
                "    conn = sqlite3.connect(DATABASE_NAME)\n",
                "    cursor = conn.cursor()\n",
                "    try:\n",
                "        cursor.execute(\"\"\"\n",
                "            INSERT INTO articles (title, date, category, url, source)\n",
                "            VALUES (?, ?, ?, ?, ?)\n",
                "        \"\"\", (title, date, category, url, source))\n",
                "        conn.commit()\n",
                "        return True\n",
                "    except sqlite3.IntegrityError:\n",
                "        return False\n",
                "    finally:\n",
                "        conn.close()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "scraping_logic",
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_total_pages():\n",
                "    try:\n",
                "        print(\"Detectando n√∫mero de p√°ginas...\")\n",
                "        r = requests.get(BASE_URL, headers=HEADERS, timeout=30)\n",
                "        soup = BeautifulSoup(r.text, \"html.parser\")\n",
                "        \n",
                "        # Tentativa 1: Busca pelo t√≠tulo 'Ir a la √∫ltima p√°gina'\n",
                "        # Exemplo HTML: <a href=\"...\" title=\"Ir a la √∫ltima p√°gina\" ...>\n",
                "        last_page_link = soup.find(\"a\", title=\"Ir a la √∫ltima p√°gina\")\n",
                "        \n",
                "        # Tentativa 2: Busca por texto '¬ª'\n",
                "        if not last_page_link:\n",
                "            last_page_link = soup.find(\"a\", string=re.compile(r'¬ª'))\n",
                "            \n",
                "        # Tentativa 3: Busca pagina√ß√£o gen√©rica e pega o maior n√∫mero\n",
                "        if not last_page_link:\n",
                "             print(\"Pagina√ß√£o '√∫ltima' n√£o encontrada, buscando maior n√∫mero nos links...\")\n",
                "             pagination_links = soup.select(\"ul.pagination li.page-item a.page-link\")\n",
                "             max_page = 0\n",
                "             for link in pagination_links:\n",
                "                 href = link.get('href', '')\n",
                "                 match = re.search(r'page=(\\d+)', href)\n",
                "                 if match:\n",
                "                     page_num = int(match.group(1))\n",
                "                     if page_num > max_page:\n",
                "                         max_page = page_num\n",
                "             if max_page > 0:\n",
                "                 return max_page\n",
                "\n",
                "        if last_page_link:\n",
                "            href = last_page_link['href']\n",
                "            print(f\"Link √∫ltima encontrado: {href}\")\n",
                "            match = re.search(r'page=(\\d+)', href)\n",
                "            if match:\n",
                "                return int(match.group(1))\n",
                "        \n",
                "        # Fallback manual em caso de falha na detec√ß√£o autom√°tica\n",
                "        # O usu√°rio informou que espera cerca de 1113 p√°ginas\n",
                "        print(\"‚ö†Ô∏è N√£o foi poss√≠vel determinar automaticamente. Usando fallback de 1113.\")\n",
                "        return 1113\n",
                "        \n",
                "    except Exception as e:\n",
                "        print(f\"Erro ao determinar total de p√°ginas: {e}\")\n",
                "        return 1113 # Segura fallback\n",
                "\n",
                "total_pages = get_total_pages()\n",
                "print(f\"Total de p√°ginas detectadas para o per√≠odo: {total_pages}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "main_loop",
            "metadata": {},
            "outputs": [],
            "source": [
                "inserted_count = 0\n",
                "\n",
                "# Itera de 0 at√© total_pages\n",
                "for page in range(total_pages + 1):\n",
                "    # Como BASE_URL j√° tem parametros, usamos &page=\n",
                "    url = f\"{BASE_URL}&page={page}\"\n",
                "    \n",
                "    # Log simplificado a cada 10 p√°ginas\n",
                "    if page % 10 == 0 or page == total_pages:\n",
                "        print(f\"Coletando p√°gina {page}/{total_pages}...\")\n",
                "    \n",
                "    try:\n",
                "        r = requests.get(url, headers=HEADERS, timeout=30)\n",
                "        if r.status_code != 200:\n",
                "            print(f\"  Status code {r.status_code} na p√°gina {page}, pulando...\")\n",
                "            continue\n",
                "            \n",
                "        soup = BeautifulSoup(r.text, \"html.parser\")\n",
                "        \n",
                "        articles = soup.find_all(\"article\")\n",
                "        \n",
                "        # Se encontrar 0, avisar (pode ser problema de parsing ou fim real)\n",
                "        if len(articles) == 0:\n",
                "             print(f\"‚ö†Ô∏è 0 not√≠cias na p√°gina {page}. Verificando parsing...\")\n",
                "        \n",
                "        for article in articles:\n",
                "            # T√≠tulo\n",
                "            title_tag = article.select_one(\"h2.node__title a span\")\n",
                "            if not title_tag:\n",
                "                title_tag = article.select_one(\"h2.node__title a\")\n",
                "            \n",
                "            if not title_tag:\n",
                "                continue\n",
                "                \n",
                "            title = title_tag.get_text(strip=True)\n",
                "            \n",
                "            # Link\n",
                "            link_tag = article.select_one(\"h2.node__title a\")\n",
                "            link = f\"https://parlamento.gub.uy{link_tag['href']}\" if link_tag else \"\"\n",
                "            \n",
                "            # Data\n",
                "            date_tag = article.select_one(\"time\")\n",
                "            date = date_tag.get_text(strip=True) if date_tag else \"\"\n",
                "            \n",
                "            # Categoria (Cuerpo)\n",
                "            cat_tag = article.select_one(\".field--name-field-noticia-cuerpo\")\n",
                "            category = cat_tag.get_text(strip=True) if cat_tag else \"Parlamento\"\n",
                "            \n",
                "            if insert_article(title, date, category, link):\n",
                "                inserted_count += 1\n",
                "        \n",
                "        # Delay pequeno para n√£o sobrecarregar\n",
                "        time.sleep(0.5)\n",
                "        \n",
                "    except Exception as e:\n",
                "        print(f\"Erro na p√°gina {page}: {e}\")\n",
                "        time.sleep(5) # Espera maior em erro\n",
                "\n",
                "print(f\"\\nüì• Total de novas not√≠cias inseridas: {inserted_count}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "analysis_load",
            "metadata": {},
            "outputs": [],
            "source": [
                "def load_articles():\n",
                "    conn = sqlite3.connect(DATABASE_NAME)\n",
                "    df = pd.read_sql(\"SELECT * FROM articles\", conn)\n",
                "    conn.close()\n",
                "    return df\n",
                "\n",
                "df_db = load_articles()\n",
                "print(f\"üì¶ Total no banco: {len(df_db)} registros\")\n",
                "display(df_db.head())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "viz",
            "metadata": {},
            "outputs": [],
            "source": [
                "if not df_db.empty:\n",
                "    # 1. Distribui√ß√£o por Categoria\n",
                "    cat_count = df_db['category'].value_counts().reset_index()\n",
                "    cat_count.columns = ['Category', 'Count']\n",
                "    \n",
                "    fig1 = px.pie(cat_count, names='Category', values='Count', title='Not√≠cias por Categoria (Cuerpo)')\n",
                "    fig1.show()\n",
                "    \n",
                "    fig2 = px.bar(cat_count, x='Category', y='Count', title='Contagem por Categoria')\n",
                "    fig2.show()\n",
                "else:\n",
                "    print(\"Sem dados para visualizar.\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}